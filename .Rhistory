##> No Noticable Difference
tbl = df_mod %>% group_by(Fever_1y) %>% summarise(median(Profit_insurance))
fig <- plot_ly(
x = tbl$Fever_1y,
y = tbl$`median(Profit_insurance)`,
name = "Fever vs Profit",
type = "bar",
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))
)
fig
tbl = df_mod %>% group_by(social_distance) %>% summarise(median(Profit_insurance))
fig <- plot_ly(
x = tbl$social_distance,
y = tbl$`median(Profit_insurance)`,
name = "Social Distance vs Profit",
type = "bar",
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))
)
fig
##> No Noticable Difference
tbl = df_mod %>% group_by(vaccin_1) %>% summarise(median(Profit_insurance))
fig <- plot_ly(
x = tbl$vaccin_1,
y = tbl$`median(Profit_insurance)`,
name = "Vaccine vs Profit",
type = "bar",
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)',
width = 1.5))
)
fig
##> No Noticable Difference
tbl = df_mod %>% group_by(medicin_ic) %>% summarise(median(Profit_insurance))
fig <- plot_ly(
x = tbl$medicin_ic,
y = tbl$`median(Profit_insurance)`,
name = "Medicin vs Profit",
type = "bar",
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))
)
fig
##> No Noticable Difference
tbl = df_mod %>% group_by(RT_PCR) %>% summarise(median(Profit_insurance))
fig <- plot_ly(
x = tbl$RT_PCR,
y = tbl$`median(Profit_insurance)`,
name = "PCR vs Profit",
type = "bar",
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))
)
fig
set.seed(200)
train_indices <- sample(nrow(df_mod), size = nrow(df_mod)*0.7, replace = FALSE)
train_new = df_mod[train_indices,]
test_new = df_mod[-train_indices,]
#### Get Info from Matrix
getInfo = function(matrix,y_pred){
return(list(
accuracy =((matrix[1,1] + matrix[2,2])/sum(matrix))*100,
sensitivity = sensitivity(matrix)*100,
specificity = specificity(matrix)*100,
auc = auc(test$Covid ,as.numeric(y_pred)),
roc = roc(response=test_new$Covid, predictor= as.numeric(y_pred))
))
}
#### Predict & Get Accuracy
getAccuracy = function(model, test_data){
y_pred = predict(model, newdata = test_data)
tab <- table(y_pred,test_new$Covid)
return(getInfo(tab,y_pred))
}
## Load Library
library(xgboost)
## Prepare data for XGBoost
test = test_new[,-c(ncol(test_new),ncol(test_new)-2)]
train = train_new[,-c(ncol(train_new),ncol(train_new)-2)]
dtrain_new <- Matrix(data.matrix(train), sparse = TRUE)
dtest_new <- Matrix(data.matrix(test), sparse = TRUE)
## Run Model
xg_new <- xgboost(dtrain_new, label = as.numeric(train$Covid)-1,
nrounds = 50, subsample = 0.8, colsample_bytree = 0.8,
early_stopping_rounds = 40, max_depth =4,
objective = "binary:logistic",
validate_parameters = TRUE,
eval_metric = "auc")
pred_new <- ifelse(predict(xg_new, dtest_new) >= 0.5, 1, 0)
tab_new <- table(pred_new, test_new$Covid)
results_xg_COVID <- getInfo(tab_new,pred_new)
results_xg_COVID
mod_da <- function(data, k, method){
control = trainControl(method="cv", number=k)
cv.da = train(
Covid~.,
data=data,
method=method,
trControl = control,
)
return(cv.da)
}
set.seed(100)
lda.fit_new <- mod_da(train_new, 10, "lda")
lda.fit_new
results_lda_Covid <- getAccuracy(lda.fit_new, test_new)
results_lda_Covid
mod_knn <- function(data, k){
control = trainControl(method="cv", number=k)
cv.knn = train(
Covid~.,
data = data,
method = "knn",
metric = "Accuracy",
trControl = control,
)
return(cv.knn)
}
knn.fit_new <- mod_knn(train_new, 10)
knn.fit_new
results_knn_Covid <- getAccuracy(knn.fit_new, test_new)
results_knn_Covid
model_results = cbind(unlist(results_xg_COVID),
unlist(results_knn_Covid),
unlist(results_lda_Covid))
colnames(model_results)  <- c("XGBoost", "KNN", "LDA")
aucs <- unlist(model_results[4,])*100
ggplot(mapping=aes(x=reorder(colnames(model_results),aucs), y=as.numeric(aucs))) +
geom_point(col="blue", stroke=1, fill="white", size=2, alpha=0.9) +
xlab("Model Name") +
ylab("Area Under the Curve AUC") +
ggtitle("Graph Representing the Obtained AUC of every Model") +
geom_label_repel(aes(label = format(round(as.numeric(aucs), 2), nsmall = 2)),
fontface = 'bold',
box.padding   = unit(0.35, "lines"),
point.padding = unit(0.3, "lines"),
segment.color = 'black') +
scale_x_discrete (expand = expansion(add=0.1))+
scale_y_continuous(limits = c(55, max(aucs)+5)) +
theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1))
rocs <- list(lda=results_lda_Covid$roc, knn=results_knn_Covid$roc,
xg=results_xg_COVID$roc)
ggroc(rocs)
### install.packages("Metrics")
### Load Metrics
library(Metrics)
#### Predict & Get Metrics
getAccuracy = function(model, test_data, pred){
return(c(
#R2
cor(test_data, pred)^2,
#MSE
mean((test_data - pred)^2),
#MAE
mean(abs(test_data - pred))
))
}
## Load Library
library(xgboost)
train_reg <- train_new[,-c(ncol(train_new),ncol(train_new)-1)]
test_reg <- train_new[,-c(ncol(test_new),ncol(test_new)-1)]
dtrain_new <- Matrix(data.matrix(train_reg), sparse = TRUE)
dtest_new <- Matrix(data.matrix(test_reg), sparse = TRUE)
## Run Model
xg_new_reg <- xgboost(dtrain_new, label = test_reg$Profit_insurance,
nrounds = 200, subsample = 0.7, colsample_bytree = 0.8,
early_stopping_rounds = 1000, max_depth =3,
objective = "reg:squarederror",
validate_parameters = TRUE,
verbose = FALSE)
pred_new <- predict(xg_new_reg, dtest_new)
xg_reg_score = getAccuracy(xg_new_reg,test_reg$Profit_insurance,pred_new)
xg_reg_score
## Import the Data to Score on later
df_score <- read.csv("score.csv")
## View top of the DF
head(df_score)
## Set Clear Characters as Factors
#install.packages("hablar")
library(hablar)
df_score <- df_score %>%
retype()
## Let's See what each column Represent
## import the data dictionary
df_dictionary <- readxl::read_xlsx("Data_dictionary.xlsx")
## Check if any of the columns is missing in the df_final
check_namings <- function(){
df_dictionary$`New_data columns`[which(!(df_dictionary$`New_data columns`
%in% colnames(df_score)))]}
check_namings()
colnames(df_score)
## Let's relocate the column `DOB` and rename it
library(tidyverse)
colnames(df_score) <- c("profit_am",colnames(df_score)[-1])
colnames(df_score)
df_score <- df_score %>%
relocate(DOB)
colnames(df_score) <- c("Age", colnames(df_score)[-1])
colnames(df_score)
## Get Scores Columns by Group | Neg vs Pos
negScores_cols = grepl("_neg",colnames(df_score))
posScores_cols = grepl("_pos",colnames(df_score))
## Get the Scores by Group
neg_scores = df_score[,negScores_cols]
head(neg_scores,n=2)
pos_scores = df_score[,posScores_cols]
head(pos_scores,n=2)
## Get the Average of each row from
neg_means = rowMeans(neg_scores, na.rm=TRUE)
head(neg_means,n=15)
pos_means = rowMeans(pos_scores, na.rm=TRUE)
head(pos_means)
#> We see many of the values are still missing
length(which(is.na(neg_means)))
length(which(is.na(pos_means)))
#> This means the customers didn't have their
#> pos & neg value assessed by any Agent.
#> Ask managment: What happened here?
#> Since there are many missing values,
#> it might be better to use Imputation techniques.
#> Removing them will result in loss of a
#> lot of samples (~1600)
## First, Drop the original columns from the DF
negScores_cols = grepl("_neg",colnames(df_score))
df_score <- df_score[,!negScores_cols]
posScores_cols = grepl("_pos",colnames(df_score))
df_score <- df_score[,!posScores_cols]
## We can see, we removed the columns
colnames(df_score)[-(0:30)]
## Add the new columns before Profit_insurance
df_score = df_score %>% add_column(neg_means)
df_score = df_score %>% add_column(pos_means)
colnames(df_score)
## Impute by Mean
df_score$pos_means[is.na(df_score$pos_means)] <- mean(df_score$pos_means, na.rm = TRUE)
df_score$neg_means[is.na(df_score$neg_means)] <- mean(df_score$neg_means, na.rm = TRUE)
## Success
length(which(is.na(df_score$pos_means)))
length(which(is.na(df_score$neg_means)))
## Remove NA
df_score$hospitalisation_bills_any[is.na(df_score$hospitalisation_bills_any)] = 0
## Success
length(which(is.na(df_score$hospitalisation_bills_any)))
## Check how many NA
length(which(is.na(df_score$individual_segment)))
## Set as Unknown
df_score$individual_segment[is.na(df_score$individual_segment)] = "Unknown"
## Success
length(which(is.na(df_score$individual_segment)))
## Check Factors
factors <- apply(df_score,2,function(x){
if(length(levels(as.factor(x)))>2){return(FALSE)}
else{return(TRUE)}
})
factors
## See the Summary to Check Numeric vs Ch
summary(df_score)
## Imput by Mean all Other than Characters
## Two Character Columns: Segment & Gender
is_ind = which(colnames(df_score)=="individual_segment")
g_ind = which(colnames(df_score)=="Gender")
## Make Factors
df_score$medicin_ic = as.factor(df_score$medicin_ic)
df_score$non_health  = as.factor(df_score$non_health)
df_score$RT_PCR  = as.factor(df_score$RT_PCR)
df_score$smoke_ic  = as.factor(df_score$smoke_ic)
df_score$Fever_6m  = as.factor(df_score$Fever_6m)
df_score$Fever_1y  = as.factor(df_score$Fever_1y)
df_score$`non.antibiotics` = as.factor(df_score$`non.antibiotics`)
df_score$home_stay = as.factor(df_score$home_stay)
df_score$vaccin_1 = as.factor(df_score$vaccin_1)
df_score$credit_use_ic = as.factor(df_score$credit_use_ic)
df_score$social_distance = as.factor(df_score$social_distance)
df_score$urban_ic = as.factor(df_score$urban_ic)
df_score$divorce = as.factor(df_score$divorce)
df_score$insurance_co = as.factor(df_score$insurance_co)
df_score$Gender = as.factor(df_score$Gender)
df_score$gold_status = as.factor(df_score$gold_status)
df_score$retired = as.factor(df_score$retired)
df_score$shop_use = as.factor(df_score$shop_use)
df_score <- as.data.frame(df_score)
for(i in 1:ncol(df_score)){
if(!(i==is_ind || i==g_ind)){
if(is.factor(df_score[,i])){
## Set all missing to 0 in case factors
df_score[,i][is.na(df_score[ , i])] <- 0
}
else{
## Imput by Mean in case NA
df_score[ , i][is.na(df_score[ , i])] <- mean(df_score[ , i], na.rm = TRUE)}
}
}
## Remove the rest NA (low count)
length(which(is.na(df_score)))
df_score <- na.omit(df_score)
length(which(is.na(df_score)))
## End of Cleaning
summary(df_score)
write.csv(df_score,"cleaned_Scoring_data.csv", row.names = FALSE)
pred_data <- df_score
pred_data
missingColumns <- setdiff(colnames(train),colnames(pred_data))
missingColumns
colnames(pred_data)[which(colnames(pred_data)=="non.antibiotics")] = "non-antibiotics"
colnames(pred_data)[which(colnames(pred_data)=="No_of.contract")] = "No_of contract"
missingColumns <- setdiff(colnames(train),colnames(pred_data))
missingColumns
pred_data[,missingColumns] <- 0
missingColumns <- setdiff(colnames(train),colnames(pred_data))
missingColumns
new_data <- Matrix(data.matrix(pred_data), sparse = TRUE)
pred_new <- ifelse(predict(xg_new, new_data) >= 0.5, 1, 0)
## None of the new people is predicted to have COVID
## Althought the model has 100% -- this is suspiscious.
length(which(pred_new>0))
pred_data <- df_score
pred_data
missingColumns <- setdiff(colnames(train_reg),colnames(pred_data))
missingColumns
colnames(pred_data)[which(colnames(pred_data)=="non.antibiotics")] = "non-antibiotics"
colnames(pred_data)[which(colnames(pred_data)=="No_of.contract")] = "No_of contract"
missingColumns <- setdiff(colnames(train_reg),colnames(pred_data))
missingColumns
pred_data[,missingColumns] <- 0
missingColumns <- setdiff(colnames(train_reg),colnames(pred_data))
missingColumns
new_data <- Matrix(data.matrix(pred_data), sparse = TRUE)
pred_new <- predict(xg_new_reg, new_data)
pred_new
order(pred_new)[0:200]
setwd("D:/Desktop/3rd Year/Spring Semester/Computational Biology/Research/Computational-Biology-Final")
source("genesurrounder/GeneSurrounder.R")
source("genesurrounder/run_geneSurrounder.R")
source("mND/calc_p.R")
## ==========================================================================
## Loading Libraries
## ==========================================================================
library(isma)
library(mND)
library(limma)
library(igraph)
library(pcaPP)
library(SciViews)
library(tidyverse)
#library(rsample)
#saveRDS(mND_score_new, "Data/mND_gs_adjusted_scores.rds")
mND_score_new <- readRDS("Data/mND_gs_adjusted_scores.rds")
mND_score <- readRDS("Data/mND_scores.rds")
mND_score
mND_score_new
#get new and old genes
new_genes = rownames(mND_score_new$mND)[which(mND_score_new$mND$mNDp < 0.05)]
old_genes = rownames(mND_score$mND)[which(mND_score$mND$mNDp < 0.05)]
## Ratio
length(which(!(new_genes %in% old_genes)))/length(rownames(mND_score$mND))
length(new_genes)
length(old_genes)
head(mND_score$mND)
## Now we are ready to start our analysis
data(X0)
X0
data(A)
A
View(A)
head(A)
X0[0:10]
X0[0:100]
X0[0:100,]
#> Take 100 genes
X0 = X0[0:100,]
A  = A [0:100,]
A
View(A)
#> Take 100 genes
X0 = X0[0:100,]
A  = A [0:100,0:100]
colnames(A)
colnames(A) == rownames(X0)
#> Take 100 genes
X0 = X0[0:100,]
A  = A [0:100,0:100]
## Normalize the Adjacency Matrix
W <- normalize_adj_mat(A)
## Permute the Layers Matrix
X0_perm <- perm_X0(X0, r = 50, W, seed_n = 2)
## Perform Network Diffusion - Non-Windows
Xs <- ND(X0_perm, W, cores = 2)
## Perform Network Diffusion - Windows
Xs <- ND(X0_perm, W)
## Perform Network Diffusion - Windows
Xs <- ND(X0_perm, W)
## Perform Network Diffusion - Non-Windows
Xs <- ND(X0_perm, W, cores = 2)
## Perform Network Diffusion - Windows
Xs <- ND(X0_perm, W)
#> Take 100 genes
X0 = X0[0:100,]
A  = A [0:100,0:100]
## Normalize the Adjacency Matrix
W <- normalize_adj_mat(A)
## Permute the Layers Matrix
X0_perm <- perm_X0(X0, r = 50, W, seed_n = 2)
W
len(W)
length(W)
#> Take 100 genes
X0 = X0[0:100,]
A  = A [0:100,0:100]
## Now we are ready to start our analysis
data(X0)
data(A)
#> Take 100 genes
X0 = X0[0:100,]
A  = A [0:100,0:100]
## Normalize the Adjacency Matrix
W <- normalize_adj_mat(A)
## Permute the Layers Matrix
X0_perm <- perm_X0(X0, r = 50, W, seed_n = 2)
## Perform Network Diffusion - Windows
Xs <- ND(X0_perm, W)
## ==========================================================================
## Analysis
## ==========================================================================
#saveRDS(mND_score_new, "Data/mND_gs_adjusted_scores.rds")
mND_score_new <- readRDS("Data/mND_gs_adjusted_scores.rds")
mND_score <- readRDS("Data/mND_scores.rds")
#get new and old genes
new_genes = rownames(mND_score_new$mND)[which(mND_score_new$mND$mNDp < 0.05)]
old_genes = rownames(mND_score$mND)[which(mND_score$mND$mNDp < 0.05)]
## Ratio
length(which(!(new_genes %in% old_genes)))/length(rownames(mND_score$mND))
length(new_genes)
length(old_genes)
##
head(mND_score$mND)
#Sanity check: L1 labels changed even more than layer 2... why?
sum(class_res_new$gene_class[,2] != class_res$gene_class[,2])
#Load Data
data(A)
W <- normalize_adj_mat(A)
ind_adj <- neighbour_index(W)
data(X0)
data(Xs)
X0_gs_adjusted <- readRDS("Data/X0_gs_adjusted.rds")
Xs_new <- readRDS("Data/Xs_new.rds")
#data(mND_score) #not same format as mND_score.rds (i think old format)
mND_score <- readRDS("Data/mND_scores.rds")
mND_score_new_k2 <- readRDS("Data/mND_gs_adjusted_scores_k2.rds")
#H1: genes with a mutation frequency greater than zero;
#H2: top 1200 differentially expressed genes (FDR < 10â7).
#Further, we set the cardinalities of gene sets N1 and N2, containing the genes with the highest scoring neighborhoods, as |H1|=|N1| and |H2|=|N2|
Hl <- list(l1 = rownames(X0[X0[,1]>0,]),
l2 = names(X0[order(X0[,2], decreasing = T),2][1:1200])
)
top_Nl <- unlist(lapply(Hl, function(x) length(x)))
top_Nl
class_res <- classification(mND_score, X0, Hl, top = top_Nl)
#Classification of genes in every layer
head(class_res$gene_class)
#Occurrence of (M; L; I; NS) for each gene across layers
head(class_res$occ_labels)
class_res
class_res
#Classification of genes in every layer
head(class_res_new$gene_class)
#Classification of genes in every layer
head(class_res_new$gene_class)
#Classification of genes in every layer
head(class_res$gene_class)
class_res$gene_class$L2
X0_gs_adjusted <- readRDS("Data/X0_gs_adjusted.rds")
Xs_new <- readRDS("Data/Xs_new.rds")
Xs_new
## ================================
Hl_old <- list(l1 = rownames(X0[X0[,1]>0,]),
l2 = names(X0[order(X0[,2], decreasing = T),2][1:1200])
)
top_Nl_old <- unlist(lapply(Hl, function(x) length(x)))
top_Nl_old
class_res_old <- classification(mND_score, X0, Hl, top = top_Nl)
head(class_res_old$gene_class)
Hl_new <- list(l1 = rownames(X0_gs_adjusted[X0_gs_adjusted[,1]>0,]),
l2 = names(X0_gs_adjusted[order(X0_gs_adjusted[,2], decreasing = T),2][1:1200])
)
top_Nl_new <- unlist(lapply(Hl_new, function(x) length(x)))
top_Nl_new
class_res_new <- classification(mND_score_new, X0_gs_adjusted, Hl_new, top = top_Nl_new)
#Classification of genes in every layer
head(class_res_new$gene_class)
#Sanity check: L1 labels changed even more than layer 2... why?
sum(class_res_new$gene_class[,2] != class_res_old$gene_class[,2])
shift_sm <- table(mND = class_res_old$gene_class[,1], GS_adjusted_mND = class_res_new$gene_class[,1])
shift_ge <- table(mND = class_res_old$gene_class[,2], GS_adjusted_mND = class_res_new$gene_class[,2])
shift_sm
shift_ge <- table(mND = class_res_old$gene_class[,2], GS_adjusted_mND = class_res_new$gene_class[,2])
shift_ge
results_ge_mND <- shift_ge
for(i in 1:nrow(shift_ge)){
results_ge_mND[i,] <- (shift_ge[i,]/sum(shift_ge[i,]))*100
}
results_ge_mND
# Percentages over GS_adjusted genes
results_ge_GS_adjusted <- shift_ge
for(i in 1:ncol(shift_ge)){
results_ge_GS_adjusted[,i] <- (shift_ge[,i]/sum(shift_ge[,i]))*100
}
results_ge_GS_adjusted
length(new_genes)
length(old_genes)
11796 - sum(shift_ge[,4])
11796 - sum(shift_ge[,4]) - (11796 - sum(shift_ge[4,]))
